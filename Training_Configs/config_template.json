{
  "--max_train_steps": 20000,
  "--checkpointing_steps": 1000,
  "--checkpoints_total_limit": 15,
  "--validation_prompt": "[enter validation prompt here.]",
  "--lora_rank": 16,
  "--flux_lora_target": "mmdit",
  "--resume_from_checkpoint": "latest",
  "--data_backend_config": "config/multidatabackend.json",
  "--aspect_bucket_rounding": 2,
  "--seed": 42,
  "--minimum_image_size": 0,
  "--output_dir": "output/models",
  "--lora_type": "lycoris",
  "--lycoris_config": "config/lycoris_config.json",
  "--num_train_epochs": 0,
  "--hub_model_id": "simpletuner-lora",
  "--tracker_project_name": "[update name of lora training run here]",
  "--tracker_run_name": "[update version of loratrain run here]",
  "--report_to": "wandb",
  "--model_type": "lora",
  "--pretrained_model_name_or_path": "black-forest-labs/FLUX.1-dev",
  "--model_family": "flux",
  "--model_flavour": "dev",
  "--train_batch_size": 1,
  "--gradient_checkpointing": "true",
  "--caption_dropout_probability": 0.1,
  "--resolution_type": "pixel_area",
  "--resolution": 1024,
  "--validation_seed": 42,
  "--validation_steps": 1000,
  "--validation_resolution": "1024x1024",
  "--validation_guidance": 3,
  "--validation_guidance_rescale": "0.0",
  "--validation_num_inference_steps": "20",
  "--mixed_precision": "bf16",
  "--optimizer": "adamw_bf16",
  "--learning_rate": "1e-4",
  "--lr_scheduler": "polynomial",
  "--lr_warmup_steps": 100,
  "--validation_torch_compile": "false",
  "--disable_benchmark": "false",
  "--base_model_precision": "int8-quanto",
  "--text_encoder_1_precision": "no_change",
  "--text_encoder_2_precision": "no_change",
  "--max_grad_norm": 1,
  "--base_model_default_dtype": "bf16"
}

#possiply useful efficiency, remove if not using
{
  "tread_config": {
    "routes": [
      {
        "selection_ratio": 0.5,
        "start_layer_idx": 2,
        "end_layer_idx": -2
      }
    ]
  }
}